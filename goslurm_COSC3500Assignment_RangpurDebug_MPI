#!/bin/bash -l
#
#SBATCH --job-name=MatrixMultiply_CPU_MPI_N2048
#SBATCH --partition=cosc3500
#SBATCH --account=cosc3500 # account is needed for cosc3500 partition
#SBATCH --nodes=2 # when doing MPI, distribute to multiple nodes
#SBATCH --ntasks-per-node=1 # ntasks = ntasks-per-node x nodes
#SBATCH --cpus-per-task=4
#SBATCH --gres gpu:0 # request for gpu
#SBATCH --time=0-00:15:00
#SBATCH --output=MatrixMultiply_CPU_MPI_N2048.stdout
#SBATCH --error=MatrixMultiply_CPU_MPI_N2048.stderr

#You could add these to your bashrc if you wanted
module load compiler-rt/latest
module add mkl/latest
module add mpi/openmpi-x86_64
module load cuda/11.1

#I would have expected the module loads to add these, but apparently not
export PATH=/opt/local/stow/cuda-11.1/bin:$PATH
export PATH=/usr/lib64/openmpi/bin:$PATH

make clean
make all
hostname
#"map-by node" (assigns processes per node. i.e. to make sure they're running on separate nodes, not all on the same node)
#"bind-to none" (for whatever reason, by default mpiexec will lock to a single core (i.e. single-threaded), bind-to none means the mpi process is free to use whatever cores it wants)
time mpiexec -n 2 -map-by node -bind-to none ./Assignment1_GradeBot 2048 4 1 0 1
